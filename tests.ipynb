{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from models.unet import UNet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(contours):\n",
    "    # Criar uma imagem binária inicializada com valores 0 (preto)\n",
    "    imagem_binaria = np.zeros((256, 256), dtype=np.uint8)\n",
    "\n",
    "    # Verificar o número de contornos\n",
    "    if len(contours) == 1:\n",
    "        # Caso haja apenas um contorno, converte e desenha diretamente\n",
    "        contornos_np = np.array(contours[0], dtype=np.int32)\n",
    "        cv2.drawContours(imagem_binaria, [contornos_np], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "    elif len(contours) == 0:\n",
    "        return imagem_binaria\n",
    "    else:\n",
    "        # Caso haja mais de um contorno, converte cada um e desenha\n",
    "        for contorno in contours:\n",
    "            contornos_np = np.array(contorno, dtype=np.int32)\n",
    "            cv2.drawContours(imagem_binaria, [contornos_np], -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    return imagem_binaria\n",
    "    \n",
    "\n",
    "def organize_masks(dataset_masks, data, camera, frame):\n",
    "    \n",
    "    dict_human = dataset_masks[f'{data}']\n",
    "    dict_robot = dataset_masks[f'{data}_robot']\n",
    "    \n",
    "    for _, all_masks_found in dict_human.items():\n",
    "        masks_data_camera = all_masks_found[f'subimage_{camera}']\n",
    "        #print(len(masks_data_camera))\n",
    "        contours_human = masks_data_camera[frame]\n",
    "    \n",
    "    for _, all_masks_found in dict_robot.items():\n",
    "        masks_data_camera = all_masks_found[f'subimage_{camera}']\n",
    "        #print(len(masks_data_camera))\n",
    "        contours_robot = masks_data_camera[frame]\n",
    "        \n",
    "        #print(contours_human)\n",
    "        \n",
    "    \n",
    "    return draw_contours(contours_human), draw_contours(contours_robot)\n",
    "        \n",
    "        \n",
    "def transform_masks(mask_human, mask_robot, mask_mode=None):\n",
    "    \n",
    "    mask_human = np.where(mask_human > 0, 1, 0)\n",
    "    mask_robot = np.where(mask_robot > 0, 1, 0)\n",
    "    \n",
    "    # Processar a máscara conforme o modo selecionado\n",
    "    if mask_mode == \"entropy\":\n",
    "        # Resolver sobreposição: prioridade para robô (ou humano, se preferir)\n",
    "        mask = np.maximum(mask_robot, mask_human)\n",
    "\n",
    "        # Converte a máscara para um tensor PyTorch e adiciona uma dimensão para o canal\n",
    "        mask_tensor = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n",
    "    else:\n",
    "        # Cria uma máscara onde cada canal representa uma classe\n",
    "        m, n = mask_human.shape\n",
    "        mask = np.zeros((3, m, n), dtype=np.float32)\n",
    "        mask[0] = 1 - (mask_human + mask_robot)  # Background\n",
    "        mask[1] = mask_human  # Humano\n",
    "        mask[2] = mask_robot  # Robô\n",
    "        # Converte a máscara para um tensor PyTorch\n",
    "        mask_tensor = torch.tensor(mask, dtype=torch.float32)\n",
    "        \n",
    "    return mask_tensor\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, masks, transform=None, mask_mode=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        self.mask_mode = mask_mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        #_, file_base_name = os.path.split(img_path)\n",
    "        file_base_name = os.path.split(img_path)[1].split(\".\")[0]\n",
    "        data, frame, camera = self.__get_mask_info__(file_base_name)\n",
    "        #print(data, frame, camera)\n",
    "        \n",
    "        mask_human, mask_robot = organize_masks(self.masks, data, int(camera), int(frame))\n",
    "        mask_tensor = transform_masks(mask_human, mask_robot, self.mask_mode)\n",
    "        \n",
    "        \n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, mask_tensor\n",
    "    \n",
    "    def __get_mask_info__(self, strx):\n",
    "        sub, act, rout, frame, camera = strx.split(\"_\")\n",
    "        return f\"{sub}_{act}_{rout}\", frame, camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_numero_regex(texto):\n",
    "    padrao = r'\\d+'\n",
    "    numeros = re.findall(padrao, texto)\n",
    "    if numeros:\n",
    "        return numeros[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_json_namefile(strx):\n",
    "\n",
    "    splited = strx.split(\"_\")\n",
    "    formated = f\"{int(extrair_numero_regex(splited[0]))}_{int(extrair_numero_regex(splited[1]))}_{int(extrair_numero_regex(splited[2]))}\"\n",
    "\n",
    "    if \"robot\" in strx:\n",
    "        formated += \"_robot\"\n",
    "        \n",
    "    return formated\n",
    "\n",
    "    \n",
    "def load_dataset_masks(pasta):\n",
    "    # Inicializa o dicionário para armazenar os dados\n",
    "    dados_json = {}\n",
    "\n",
    "    # Lista todos os arquivos na pasta\n",
    "    arquivos = os.listdir(pasta)\n",
    "\n",
    "    # Filtra apenas os arquivos JSON\n",
    "    arquivos_json = [arquivo for arquivo in arquivos if arquivo.endswith('.json')]\n",
    "\n",
    "    # Processa cada arquivo JSON encontrado\n",
    "    for arquivo_json in tqdm(arquivos_json):\n",
    "        caminho_completo = os.path.join(pasta, arquivo_json)\n",
    "        nome_arquivo = os.path.basename(arquivo_json)\n",
    "\n",
    "        # Carrega o conteúdo do arquivo JSON como um dicionário\n",
    "        with open(caminho_completo, 'r', encoding='utf-8') as f:\n",
    "            conteudo = json.load(f)\n",
    "        \n",
    "        # Adiciona ao dicionário final usando o nome do arquivo como chave\n",
    "        dados_json[process_json_namefile(nome_arquivo)] = conteudo\n",
    "    \n",
    "    return dados_json\n",
    "\n",
    "\n",
    "def load_image_paths(directory):\n",
    "    \"\"\"Loads all image paths from the specified directory.\"\"\"\n",
    "    path = Path(directory)\n",
    "    image_paths = list(path.glob('*.jpg'))\n",
    "    return [str(img) for img in image_paths]\n",
    "\n",
    "\n",
    "def group_images_by_prefix(image_paths):\n",
    "    \"\"\"Groups images by their prefix NUMSUBJECT_NUMACTIVITY_NUM_ROUTINE.\"\"\"\n",
    "    pattern = re.compile(r'(\\d+)_(\\d+)_(\\d+)_\\d+_\\d+.jpg')\n",
    "    grouped = {}\n",
    "    for img_path in image_paths:\n",
    "        match = pattern.search(os.path.basename(img_path))\n",
    "        if match:\n",
    "            prefix = f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "            if prefix not in grouped:\n",
    "                grouped[prefix] = []\n",
    "            grouped[prefix].append(img_path)\n",
    "    return list(grouped.values())\n",
    "\n",
    "\n",
    "def create_dataloaders(image_groups, dataset_masks, n_splits=5, batch_size=32, transform=None, mask_mode=None):\n",
    "    \"\"\"Creates DataLoaders for cross-validation.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    dataloaders = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(image_groups):\n",
    "        train_images = [img for i in train_index for img in image_groups[i]]\n",
    "        val_images = [img for i in val_index for img in image_groups[i]]\n",
    "        \n",
    "        train_dataset = CustomImageDataset(train_images, dataset_masks, transform, mask_mode)\n",
    "        val_dataset = CustomImageDataset(val_images, dataset_masks, transform, mask_mode)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "def show_masks(mask):\n",
    "    plt.imshow(mask, cmap='gray')  # cmap='gray' garante que a imagem será mostrada em tons de cinza\n",
    "    plt.title('Imagem de um canal')\n",
    "    plt.colorbar()  # Adiciona uma barra de cores para referência\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        fold = checkpoint['fold']\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        return epoch, fold, best_val_loss\n",
    "    else:\n",
    "        print(f\"No checkpoint found at: {checkpoint_path}\")\n",
    "        return 0, 0, float('inf')\n",
    "    \n",
    "\n",
    "# Função para salvar checkpoints\n",
    "def save_checkpoint(model, optimizer, epoch, fold, is_best, checkpoint_dir, model_type):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"{model_type}_epoch{epoch}_fold{fold}.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'fold': fold,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    if is_best:\n",
    "        best_checkpoint_path = os.path.join(checkpoint_dir, f\"best_{model_type}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'fold': fold,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, best_checkpoint_path)\n",
    "        \n",
    "\n",
    "# Função para calcular métricas\n",
    "def calculate_metrics(outputs, targets):\n",
    "    # Placeholder function: Implement Dice, IoU, etc.\n",
    "    mean_dice = 0.0\n",
    "    mean_iou = 0.0\n",
    "    dice_per_class = [0.0, 0.0, 0.0]\n",
    "    iou_per_class = [0.0, 0.0, 0.0]\n",
    "    return mean_dice, mean_iou, dice_per_class, iou_per_class\n",
    "\n",
    "\n",
    "# Função para salvar métricas em CSV\n",
    "def save_metrics_to_csv(metrics, loss, phase, checkpoint_dir, fold):\n",
    "    metrics_df = pd.DataFrame(metrics, columns=[\"mean_dice\", \"mean_iou\", \"dice_per_class\", \"iou_per_class\"])\n",
    "    metrics_df[\"loss\"] = loss\n",
    "    metrics_df[\"phase\"] = phase\n",
    "\n",
    "    csv_path = os.path.join(checkpoint_dir, f\"fold{fold+1}_report.csv\")\n",
    "    if not os.path.isfile(csv_path):\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        \n",
    "\n",
    "# Função para treinar e validar o modelo\n",
    "def train_and_validate(model, dataloaders, num_epochs, criterion, optimizer, checkpoint_dir):\n",
    "    \n",
    "    # Inicialize a variável best_val_loss no início da função train_and_validate\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    # Dentro do loop de treinamento e validação\n",
    "    for fold, (train_loader, val_loader) in enumerate(dataloaders):\n",
    "        print(f\"Fold {fold+1}/{len(dataloaders)}\")\n",
    "        start_epoch, _, best_val_loss = load_checkpoint(model, optimizer, os.path.join(checkpoint_dir, f\"fold{fold+1}.pth\"))\n",
    "\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            train_metrics = []\n",
    "\n",
    "            train_pbar = tqdm(train_loader, desc=f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "            for images, masks in train_pbar:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                masks = masks.long()\n",
    "                loss = criterion(outputs, masks.squeeze(1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "\n",
    "                # Calculate metrics\n",
    "                mean_dice, mean_iou, dice_per_class, iou_per_class = calculate_metrics(outputs, masks)\n",
    "                train_metrics.append((mean_dice, mean_iou, dice_per_class, iou_per_class))\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            train_pbar.set_postfix({\"loss\": epoch_loss})\n",
    "            save_checkpoint(model, optimizer, epoch, fold, False, checkpoint_dir, \"train\")\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_metrics = []\n",
    "            with torch.no_grad():\n",
    "                val_pbar = tqdm(val_loader, desc=f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "                for images, masks in val_pbar:\n",
    "                    outputs = model(images)\n",
    "                    masks = masks.long()\n",
    "                    loss = criterion(outputs, masks.squeeze(1))\n",
    "                    val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    mean_dice, mean_iou, dice_per_class, iou_per_class = calculate_metrics(outputs, masks)\n",
    "                    val_metrics.append((mean_dice, mean_iou, dice_per_class, iou_per_class))\n",
    "\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "            val_pbar.set_postfix({\"loss\": val_loss})\n",
    "\n",
    "            # Save best model based on validation loss\n",
    "            is_best = val_loss < best_val_loss\n",
    "            if is_best:\n",
    "                best_val_loss = val_loss\n",
    "            save_checkpoint(model, optimizer, epoch, fold, is_best, checkpoint_dir, \"val\")\n",
    "\n",
    "            # Save metrics to CSV\n",
    "            save_metrics_to_csv(train_metrics, epoch_loss, \"train\", checkpoint_dir, fold)\n",
    "            save_metrics_to_csv(val_metrics, val_loss, \"val\", checkpoint_dir, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = \"C:/Users/iagor/Documents/git/data-definer/out/\"\n",
    "mask_directory = \"C:/Users/iagor/Documents/git/human-segmentation-sam/out/\"\n",
    "checkpoint_dir = \"checkpoints/\"\n",
    "batch_size = 4\n",
    "n_splits = 5\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 53/216 [00:15<00:21,  7.47it/s]"
     ]
    }
   ],
   "source": [
    "dataset_masks = load_dataset_masks(mask_directory)\n",
    "mask_mode = \"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = UNet(n_channels=3, n_classes=3, bilinear=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "No checkpoint found at: checkpoints/fold1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/10:   0%|          | 0/56 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "image_paths = load_image_paths(image_directory)\n",
    "image_groups = group_images_by_prefix(image_paths)\n",
    "dataloaders = create_dataloaders(image_groups, dataset_masks, n_splits, batch_size, transform, mask_mode) \n",
    "train_and_validate(model, dataloaders, num_epochs, criterion, optimizer, checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iago",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
