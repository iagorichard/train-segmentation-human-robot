{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iago/miniconda3/envs/phd_updated_v2/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from models.unet import UNet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(contours):\n",
    "    # Criar uma imagem binária inicializada com valores 0 (preto)\n",
    "    imagem_binaria = np.zeros((256, 256), dtype=np.uint8)\n",
    "\n",
    "    # Verificar o número de contornos\n",
    "    if len(contours) == 1:\n",
    "        # Caso haja apenas um contorno, converte e desenha diretamente\n",
    "        contornos_np = np.array(contours[0], dtype=np.int32)\n",
    "        cv2.drawContours(imagem_binaria, [contornos_np], -1, (1, 1, 1), thickness=cv2.FILLED)\n",
    "    elif len(contours) == 0:\n",
    "        return imagem_binaria\n",
    "    else:\n",
    "        # Caso haja mais de um contorno, converte cada um e desenha\n",
    "        for contorno in contours:\n",
    "            contornos_np = np.array(contorno, dtype=np.int32)\n",
    "            cv2.drawContours(imagem_binaria, [contornos_np], -1, (1, 1, 1), thickness=cv2.FILLED)\n",
    "\n",
    "    return imagem_binaria\n",
    "    \n",
    "\n",
    "def organize_masks(dataset_masks, data, camera, frame):\n",
    "    \n",
    "    dict_human = dataset_masks[f'{data}']\n",
    "    dict_robot = dataset_masks[f'{data}_robot']\n",
    "    \n",
    "    for _, all_masks_found in dict_human.items():\n",
    "        masks_data_camera = all_masks_found[f'subimage_{camera}']\n",
    "        #print(len(masks_data_camera))\n",
    "        contours_human = masks_data_camera[frame]\n",
    "    \n",
    "    for _, all_masks_found in dict_robot.items():\n",
    "        masks_data_camera = all_masks_found[f'subimage_{camera}']\n",
    "        #print(len(masks_data_camera))\n",
    "        contours_robot = masks_data_camera[frame]\n",
    "        \n",
    "        #print(contours_human)\n",
    "        \n",
    "    \n",
    "    return draw_contours(contours_human), draw_contours(contours_robot)\n",
    "        \n",
    "        \n",
    "def transform_masks(mask_human, mask_robot, mask_mode=None):\n",
    "    # Converter as máscaras para binário (0 ou 1)\n",
    "    mask_human = np.where(mask_human > 0, 1, 0)\n",
    "    mask_robot = np.where(mask_robot > 0, 1, 0)\n",
    "    \n",
    "    # Cria a máscara final combinando as classes\n",
    "    if mask_mode == \"entropy\":\n",
    "        # Resolver sobreposição dando prioridade para robôs\n",
    "        mask = np.where(mask_robot == 1, 2, mask_human)  # Robô = 2, Humano = 1\n",
    "    else:\n",
    "        # Resolver a máscara criando três classes: 0 (background), 1 (humano), 2 (robô)\n",
    "        mask = np.zeros_like(mask_human)  # Inicializar com background (0)\n",
    "        mask[mask_human == 1] = 1  # Definir classe humano como 1\n",
    "        mask[mask_robot == 1] = 2  # Definir classe robô como 2, sobrepõe humano se necessário\n",
    "\n",
    "    # Converte a máscara para um tensor PyTorch\n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.long)\n",
    "    \n",
    "    return mask_tensor\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, masks, transform=None, mask_mode=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        self.mask_mode = mask_mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        #_, file_base_name = os.path.split(img_path)\n",
    "        file_base_name = os.path.split(img_path)[1].split(\".\")[0]\n",
    "        data, frame, camera = self.__get_mask_info__(file_base_name)\n",
    "        #print(data, frame, camera)\n",
    "        \n",
    "        mask_human, mask_robot = organize_masks(self.masks, data, int(camera), int(frame))\n",
    "        #mask_tensor = transform_masks(mask_human, mask_robot, self.mask_mode)\n",
    "        \n",
    "        m0 = np.zeros_like(mask_human)\n",
    "        final_mask = cv2.merge((m0, mask_robot, mask_human))\n",
    "        mask_tensor = np.transpose(final_mask, (2,0,1))\n",
    "        #print(f\"Mask human: {mask_human.shape}\")\n",
    "        #print(f\"Mask robot: {mask_robot.shape}\")\n",
    "\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        img_nd = np.array(image)\n",
    "\n",
    "        if len(img_nd.shape) == 2:\n",
    "            img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "        img_trans = img_nd.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "        #if self.transform:\n",
    "        #    image = self.transform(image)\n",
    "\n",
    "\n",
    "\n",
    "        return torch.from_numpy(img_trans).type(torch.FloatTensor), torch.from_numpy(mask_tensor).type(torch.FloatTensor)\n",
    "    \n",
    "    def __get_mask_info__(self, strx):\n",
    "        sub, act, rout, frame, camera = strx.split(\"_\")\n",
    "        return f\"{sub}_{act}_{rout}\", frame, camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_numero_regex(texto):\n",
    "    padrao = r'\\d+'\n",
    "    numeros = re.findall(padrao, texto)\n",
    "    if numeros:\n",
    "        return numeros[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_json_namefile(strx):\n",
    "\n",
    "    splited = strx.split(\"_\")\n",
    "    formated = f\"{int(extrair_numero_regex(splited[0]))}_{int(extrair_numero_regex(splited[1]))}_{int(extrair_numero_regex(splited[2]))}\"\n",
    "\n",
    "    if \"robot\" in strx:\n",
    "        formated += \"_robot\"\n",
    "        \n",
    "    return formated\n",
    "\n",
    "    \n",
    "def load_dataset_masks(pasta):\n",
    "    # Inicializa o dicionário para armazenar os dados\n",
    "    dados_json = {}\n",
    "\n",
    "    # Lista todos os arquivos na pasta\n",
    "    arquivos = os.listdir(pasta)\n",
    "\n",
    "    # Filtra apenas os arquivos JSON\n",
    "    arquivos_json = [arquivo for arquivo in arquivos if arquivo.endswith('.json')]\n",
    "\n",
    "    # Processa cada arquivo JSON encontrado\n",
    "    for arquivo_json in tqdm(arquivos_json):\n",
    "        caminho_completo = os.path.join(pasta, arquivo_json)\n",
    "        nome_arquivo = os.path.basename(arquivo_json)\n",
    "\n",
    "        # Carrega o conteúdo do arquivo JSON como um dicionário\n",
    "        with open(caminho_completo, 'r', encoding='utf-8') as f:\n",
    "            conteudo = json.load(f)\n",
    "        \n",
    "        # Adiciona ao dicionário final usando o nome do arquivo como chave\n",
    "        dados_json[process_json_namefile(nome_arquivo)] = conteudo\n",
    "    \n",
    "    return dados_json\n",
    "\n",
    "\n",
    "def load_image_paths(directory):\n",
    "    \"\"\"Loads all image paths from the specified directory.\"\"\"\n",
    "    path = Path(directory)\n",
    "    image_paths = list(path.glob('*.jpg'))\n",
    "    return [str(img) for img in image_paths]\n",
    "\n",
    "\n",
    "def group_images_by_prefix(image_paths):\n",
    "    \"\"\"Groups images by their prefix NUMSUBJECT_NUMACTIVITY_NUM_ROUTINE.\"\"\"\n",
    "    pattern = re.compile(r'(\\d+)_(\\d+)_(\\d+)_\\d+_\\d+.jpg')\n",
    "    grouped = {}\n",
    "    for img_path in image_paths:\n",
    "        match = pattern.search(os.path.basename(img_path))\n",
    "        if match:\n",
    "            prefix = f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "            if prefix not in grouped:\n",
    "                grouped[prefix] = []\n",
    "            grouped[prefix].append(img_path)\n",
    "    return list(grouped.values())\n",
    "\n",
    "\n",
    "def create_dataloaders(image_groups, dataset_masks, n_splits=5, batch_size=32, transform=None, mask_mode=None):\n",
    "    \"\"\"Creates DataLoaders for cross-validation.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    dataloaders = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(image_groups):\n",
    "        train_images = [img for i in train_index for img in image_groups[i]]\n",
    "        val_images = [img for i in val_index for img in image_groups[i]]\n",
    "        \n",
    "        train_dataset = CustomImageDataset(train_images, dataset_masks, transform, mask_mode)\n",
    "        val_dataset = CustomImageDataset(val_images, dataset_masks, transform, mask_mode)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "def show_masks(mask):\n",
    "    plt.imshow(mask, cmap='gray')  # cmap='gray' garante que a imagem será mostrada em tons de cinza\n",
    "    plt.title('Imagem de um canal')\n",
    "    plt.colorbar()  # Adiciona uma barra de cores para referência\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_checkpoint_info(checkpoint_dir):\n",
    "    \n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    folds = [int(fold_dir.replace('fold', '')) for fold_dir in os.listdir(checkpoint_dir)\n",
    "             if fold_dir.startswith('fold') and os.path.isdir(os.path.join(checkpoint_dir, fold_dir))]\n",
    "    if not folds:\n",
    "        return 0, 0, float('inf')  # No existing folds, start from scratch\n",
    "    last_fold = max(folds)\n",
    "    last_checkpoint_path = os.path.join(checkpoint_dir, f\"fold{last_fold}\", \"last_training_loss.pth\")\n",
    "    if os.path.isfile(last_checkpoint_path):\n",
    "        epoch, fold, best_val_loss = load_checkpoint(None, None, last_checkpoint_path, return_model=False)\n",
    "        return epoch, last_fold, best_val_loss\n",
    "    else:\n",
    "        return 0, last_fold - 1, float('inf')  # No valid checkpoint, restart the last fold\n",
    "\n",
    "    \n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, return_model=True):\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        if return_model and model is not None and optimizer is not None:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        fold = checkpoint['fold']\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        return epoch, fold, best_val_loss\n",
    "    else:\n",
    "        print(f\"No checkpoint found at: {checkpoint_path}\")\n",
    "        return 0, 0, float('inf')\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, fold, is_best, checkpoint_dir):\n",
    "    # Cria o diretório de checkpoints e subdiretório para cada fold, se não existirem\n",
    "    fold_dir = os.path.join(checkpoint_dir, f\"fold{fold+1}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "    \n",
    "    # Caminho para o último checkpoint de treinamento\n",
    "    last_checkpoint_path = os.path.join(fold_dir, \"last_training_loss.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'fold': fold,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, last_checkpoint_path)\n",
    "\n",
    "    if is_best:\n",
    "        best_checkpoint_path = os.path.join(fold_dir, \"best_val_loss.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'fold': fold,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, best_checkpoint_path)\n",
    "        \n",
    "\n",
    "def calculate_dice_coefficient(outputs, targets, smooth=1e-6):\n",
    "    outputs = outputs.argmax(dim=1)  # Convert output logits to class predictions\n",
    "    num_classes = 3  # Defina o número de classes explicitamente\n",
    "\n",
    "    dice_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        intersection = ((outputs == i) & (targets == i)).float().sum()\n",
    "        union = (outputs == i).float().sum() + (targets == i).float().sum()\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_per_class.append(dice.item())\n",
    "\n",
    "    mean_dice = sum(dice_per_class) / num_classes\n",
    "    return mean_dice, dice_per_class\n",
    "\n",
    "def calculate_iou(outputs, targets, smooth=1e-6):\n",
    "    outputs = outputs.argmax(dim=1)  # Convert output logits to class predictions\n",
    "    num_classes = 3  # Defina o número de classes explicitamente\n",
    "\n",
    "    iou_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        intersection = ((outputs == i) & (targets == i)).float().sum()\n",
    "        union = ((outputs == i) | (targets == i)).float().sum()\n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        iou_per_class.append(iou.item())\n",
    "\n",
    "    mean_iou = sum(iou_per_class) / num_classes\n",
    "    return mean_iou, iou_per_class\n",
    "\n",
    "def calculate_metrics(outputs, targets):\n",
    "    mean_dice, dice_per_class = calculate_dice_coefficient(outputs, targets)\n",
    "    mean_iou, iou_per_class = calculate_iou(outputs, targets)\n",
    "    return mean_dice, mean_iou, dice_per_class, iou_per_class\n",
    "\n",
    "\n",
    "def save_metrics_to_csv(metrics_train, loss_train, metrics_val, loss_val, checkpoint_dir, fold, epoch):\n",
    "    # Cria o diretório de checkpoints, se não existir\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Separar as métricas\n",
    "    mean_dice_train, mean_iou_train, dice_per_class_train, iou_per_class_train = zip(*metrics_train)\n",
    "    mean_dice_val, mean_iou_val, dice_per_class_val, iou_per_class_val = zip(*metrics_val)\n",
    "    \n",
    "    # Calcular as médias\n",
    "    avg_dice_train = np.mean(mean_dice_train)\n",
    "    avg_iou_train = np.mean(mean_iou_train)\n",
    "    avg_dice_val = np.mean(mean_dice_val)\n",
    "    avg_iou_val = np.mean(mean_iou_val)\n",
    "    \n",
    "    # Preparar os dados para o DataFrame\n",
    "    data = {\n",
    "        'epoch': epoch,\n",
    "        'loss_train': loss_train,\n",
    "        'loss_val': loss_val,\n",
    "        'avg_dice_train': avg_dice_train,\n",
    "        'avg_iou_train': avg_iou_train,\n",
    "        'avg_dice_val': avg_dice_val,\n",
    "        'avg_iou_val': avg_iou_val,\n",
    "    }\n",
    "\n",
    "    # Adicionar métricas por classe\n",
    "    for class_index in range(3):  # Assumindo 3 classes: fundo, humano, robô\n",
    "        data[f'dice_class_{class_index}_train'] = np.mean([d[class_index] for d in dice_per_class_train])\n",
    "        data[f'iou_class_{class_index}_train'] = np.mean([i[class_index] for i in iou_per_class_train])\n",
    "        data[f'dice_class_{class_index}_val'] = np.mean([d[class_index] for d in dice_per_class_val])\n",
    "        data[f'iou_class_{class_index}_val'] = np.mean([i[class_index] for i in iou_per_class_val])\n",
    "    \n",
    "    # Converter para DataFrame\n",
    "    metrics_df = pd.DataFrame([data])\n",
    "\n",
    "    csv_path = os.path.join(checkpoint_dir, f\"fold{fold+1}_report.csv\")\n",
    "    if not os.path.isfile(csv_path):\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "        \n",
    "\n",
    "def get_sampled_loader(data_loader, sample_percentage):\n",
    "    # Calcula o tamanho da amostra\n",
    "    sample_size = int(len(data_loader.dataset) * sample_percentage)\n",
    "    remaining_size = len(data_loader.dataset) - sample_size\n",
    "    \n",
    "    # Divide o dataset em duas partes: amostra e restante\n",
    "    sample_dataset, _ = random_split(data_loader.dataset, [sample_size, remaining_size])\n",
    "    \n",
    "    # Cria um novo DataLoader para a amostra\n",
    "    sampled_loader = DataLoader(sample_dataset, batch_size=data_loader.batch_size, shuffle=True)\n",
    "    \n",
    "    return sampled_loader\n",
    "\n",
    "def train_and_validate(original_model, dataloaders, num_epochs, criterion, optimizer, checkpoint_dir, sampling=None):\n",
    "    start_epoch, start_fold, best_val_loss = get_last_checkpoint_info(checkpoint_dir)\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1, verbose=True)\n",
    "\n",
    "\n",
    "    \n",
    "    for fold in range(start_fold, len(dataloaders)):\n",
    "        model = copy.deepcopy(original_model).to(device)\n",
    "        train_loader, val_loader = dataloaders[fold]\n",
    "        \n",
    "        if sampling is not None:\n",
    "            train_loader = get_sampled_loader(train_loader, sampling)\n",
    "            val_loader = get_sampled_loader(val_loader, sampling)\n",
    "        \n",
    "        print(f\"Fold {fold+1}/{len(dataloaders)}\")\n",
    "        \n",
    "        # If continuing an interrupted training, load the last checkpoint\n",
    "        if fold == start_fold and start_epoch > 0:\n",
    "            start_epoch, _, best_val_loss = load_checkpoint(model, optimizer, os.path.join(checkpoint_dir, f\"fold{fold+1}\", \"last_training_loss.pth\"))\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "        \n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            train_metrics = []\n",
    "\n",
    "            train_pbar = tqdm(train_loader, desc=f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "            for images, masks in train_pbar:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                masks = masks.squeeze(1)\n",
    "\n",
    "                #print(images.shape, masks.shape)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                masks = masks.long()\n",
    "                \n",
    "                #print(torch.max(outputs), torch.min(outputs), torch.mean(outputs))\n",
    "\n",
    "\n",
    "\n",
    "                #print(images.shape, masks.shape)\n",
    "                #loss = criterion(outputs, masks.squeeze(1))\n",
    "                loss = criterion(outputs, masks) + dice_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                train_pbar.set_postfix({\"batch_loss\": loss.item()})\n",
    "\n",
    "                # Calculate metrics\n",
    "                mean_dice, mean_iou, dice_per_class, iou_per_class = calculate_metrics(outputs, masks)\n",
    "                train_metrics.append((mean_dice, mean_iou, dice_per_class, iou_per_class))\n",
    "\n",
    "            epoch_loss_train = running_loss / len(train_loader.dataset)\n",
    "            train_pbar.set_postfix({\"loss\": epoch_loss_train})\n",
    "            save_checkpoint(model, optimizer, epoch, fold, False, checkpoint_dir)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            running_loss_val = 0.0\n",
    "            val_metrics = []\n",
    "            with torch.no_grad():\n",
    "                val_pbar = tqdm(val_loader, desc=f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "                for images, masks in val_pbar:\n",
    "                    images, masks = images.to(device), masks.to(device)\n",
    "                    outputs = model(images)\n",
    "                    masks = masks.long()\n",
    "                    val_loss = criterion(outputs, masks) + dice_loss(outputs, masks)\n",
    "                    running_loss_val += val_loss.item() * images.size(0)\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    mean_dice, mean_iou, dice_per_class, iou_per_class = calculate_metrics(outputs, masks)\n",
    "                    val_metrics.append((mean_dice, mean_iou, dice_per_class, iou_per_class))\n",
    "\n",
    "            epoch_loss_val = running_loss_val / len(val_loader.dataset)\n",
    "            val_pbar.set_postfix({\"loss\": epoch_loss_val})\n",
    "\n",
    "            scheduler.step(epoch_loss_val) #SCHEDULER\n",
    "\n",
    "            # Save best model based on validation loss\n",
    "            is_best = epoch_loss_val < best_val_loss\n",
    "            if is_best:\n",
    "                best_val_loss = epoch_loss_val\n",
    "            save_checkpoint(model, optimizer, epoch, fold, is_best, checkpoint_dir)\n",
    "\n",
    "            # Save metrics to CSV\n",
    "            save_metrics_to_csv(train_metrics, epoch_loss_train, val_metrics, epoch_loss_val, checkpoint_dir, fold, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for individual examples\"\"\"\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "\n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    def backward(self, grad_output):\n",
    "\n",
    "        input, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "\n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
    "                         / (self.union * self.union)\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "\n",
    "        return grad_input, grad_target\n",
    "\n",
    "def evaluation_v2(net, loader, device):\n",
    "    \"\"\"Evaluation without the densecrf with the dice coefficient\"\"\"\n",
    "    net.eval()\n",
    "    mask_type = torch.float32 if net.segmentation_head[0].out_channels == 1 else torch.long\n",
    "    n_val = len(loader)  # the number of batch\n",
    "    tot_iou = 0\n",
    "    tot_dice = 0\n",
    "    tot = 0\n",
    "\n",
    "    #for batch in tqdm(loader):\n",
    "    print(\"evaluating...\")\n",
    "    for batch in tqdm(loader):\n",
    "        imgs, true_masks = batch['image'], batch['mask']\n",
    "        imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "        true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mask_pred = net(imgs)\n",
    "\n",
    "        if net.segmentation_head[0].out_channels > 1:\n",
    "            true_masks = torch.argmax(true_masks, 1)\n",
    "            tot += F.cross_entropy(mask_pred, true_masks).item()\n",
    "\n",
    "            #tot_dice += dice_coeff(pred, true_masks).item()\n",
    "            #tot_iou += iou(transform(pred), transform(true_masks))\n",
    "        else:\n",
    "            pred = torch.sigmoid(mask_pred)\n",
    "            pred = (pred > 0.5).float()\n",
    "            \n",
    "            tot_dice += dice_coeff(pred, true_masks).item()\n",
    "            tot_iou += iou(transform(pred), transform(true_masks))\n",
    "\n",
    "    net.train()\n",
    "    return tot / n_val\n",
    "\n",
    "#dice_loss = DiceLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_directory = \"C:/Users/iagor/Documents/git/data-definer/out/\"\n",
    "image_directory = \"/home/iago/PhD/data-definer/out/\"\n",
    "#mask_directory = \"C:/Users/iagor/Documents/git/human-segmentation-sam/out/\"\n",
    "mask_directory = \"/home/iago/PhD/segment-humans-sam/out/\"\n",
    "batch_size = 4\n",
    "n_splits = 5\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()  # Converte automaticamente para o intervalo [0, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_masks = load_dataset_masks(mask_directory)\n",
    "mask_mode = \"entropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = UNet(n_channels=3, n_classes=3, bilinear=True)\n",
    "checkpoint_dir = \"checkpoints/EUVOUMURRERRRRRRRRRRR/\"\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "weights = torch.tensor([0.5, 1.0, 1.0]).to(device)  # Ajuste os pesos conforme necessário\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "\n",
    "sampling = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = load_image_paths(image_directory)\n",
    "image_groups = group_images_by_prefix(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_dataloaders(image_groups, dataset_masks, n_splits, batch_size, transform, mask_mode) \n",
    "#dataloaders = create_dataloaders(image_paths, dataset_masks, n_splits, batch_size, transform, mask_mode) \n",
    "train_and_validate(model, dataloaders, num_epochs, criterion, optimizer, checkpoint_dir, sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_masks(dataloader):\n",
    "    # Obtenha o primeiro batch do dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    images, masks = next(dataiter)\n",
    "    \n",
    "    batch_size = images.size(0)\n",
    "    \n",
    "    fig, axs = plt.subplots(batch_size, 2, figsize=(10, batch_size * 5))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Converta o tensor da imagem para numpy para exibição\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        mask = masks[i].squeeze(0).cpu().numpy()  # Remove a dimensão extra da máscara\n",
    "\n",
    "        print(img.shape)\n",
    "        print(f\"{mask.shape} - {np.unique(mask)}\")\n",
    "        \n",
    "        # Normalize the image for display purposes (optional)\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            axs[0].imshow(img)\n",
    "            axs[0].set_title(f\"Image {i + 1}\")\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            axs[1].imshow(mask, cmap='gray')\n",
    "            axs[1].set_title(f\"Mask {i + 1}\")\n",
    "            axs[1].axis('off')\n",
    "        else:\n",
    "            axs[i, 0].imshow(img)\n",
    "            axs[i, 0].set_title(f\"Image {i + 1}\")\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            axs[i, 1].imshow(mask, cmap='gray')\n",
    "            axs[i, 1].set_title(f\"Mask {i + 1}\")\n",
    "            axs[i, 1].axis('off')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_masks(dataloaders[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloaders[0][0])\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_sampled_loader(dataloaders[0][0], sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = dataloaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)  # substitua `train_loader` pelo seu DataLoader\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in images:\n",
    "    print(im.shape)\n",
    "    print(torch.unique(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshou(img):\n",
    "    img = img / 2 + 0.5  # Dessormalizar (se as imagens foram normalizadas)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "imshou(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshou(torchvision.utils.make_grid(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iago",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
