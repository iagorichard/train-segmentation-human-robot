{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from models.unet import UNet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import copy\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.autograd import Function\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import jaccard_score as iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, encoder):\n",
    "\n",
    "    if model_name == \"unet\":\n",
    "        return smp.Unet(encoder_name=encoder, encoder_weights=\"imagenet\", in_channels=3, classes=3)\n",
    "    elif model_name == \"linknet\":\n",
    "        return smp.Linknet(encoder_name=encoder, encoder_weights=\"imagenet\", in_channels=3, classes=3)\n",
    "    elif model_name == \"pan\":\n",
    "        return smp.PAN(encoder_name=encoder, encoder_weights=\"imagenet\", in_channels=3, classes=3)\n",
    "    elif model_name == \"deeplab\":\n",
    "        return smp.DeepLabV3(encoder_name=encoder, encoder_weights=\"imagenet\", in_channels=3, classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(contours):\n",
    "    # Criar uma imagem binária inicializada com valores 0 (preto)\n",
    "    imagem_binaria = np.zeros((256, 256), dtype=np.uint8)\n",
    "\n",
    "    # Verificar o número de contornos\n",
    "    if len(contours) == 1:\n",
    "        # Caso haja apenas um contorno, converte e desenha diretamente\n",
    "        contornos_np = np.array(contours[0], dtype=np.int32)\n",
    "        cv2.drawContours(imagem_binaria, [contornos_np], -1, (1, 1, 1), thickness=cv2.FILLED)\n",
    "    elif len(contours) == 0:\n",
    "        return imagem_binaria\n",
    "    else:\n",
    "        # Caso haja mais de um contorno, converte cada um e desenha\n",
    "        for contorno in contours:\n",
    "            contornos_np = np.array(contorno, dtype=np.int32)\n",
    "            cv2.drawContours(imagem_binaria, [contornos_np], -1, (1, 1, 1), thickness=cv2.FILLED)\n",
    "\n",
    "    return imagem_binaria\n",
    "    \n",
    "\n",
    "def organize_masks(dataset_masks, data, camera, frame):\n",
    "    \n",
    "    dict_human = dataset_masks[f'{data}']\n",
    "    dict_robot = dataset_masks[f'{data}_robot']\n",
    "    \n",
    "    for _, all_masks_found in dict_human.items():\n",
    "        masks_data_camera = all_masks_found[f'subimage_{camera}']\n",
    "        #print(len(masks_data_camera))\n",
    "        contours_human = masks_data_camera[frame]\n",
    "    \n",
    "    for _, all_masks_found in dict_robot.items():\n",
    "        masks_data_camera = all_masks_found[f'subimage_{camera}']\n",
    "        #print(len(masks_data_camera))\n",
    "        contours_robot = masks_data_camera[frame]\n",
    "        \n",
    "        #print(contours_human)\n",
    "        \n",
    "    \n",
    "    return draw_contours(contours_human), draw_contours(contours_robot)\n",
    "        \n",
    "        \n",
    "def transform_masks(mask_human, mask_robot, mask_mode=None):\n",
    "    # Converter as máscaras para binário (0 ou 1)\n",
    "    mask_human = np.where(mask_human > 0, 1, 0)\n",
    "    mask_robot = np.where(mask_robot > 0, 1, 0)\n",
    "    \n",
    "    # Cria a máscara final combinando as classes\n",
    "    if mask_mode == \"entropy\":\n",
    "        # Resolver sobreposição dando prioridade para robôs\n",
    "        mask = np.where(mask_robot == 1, 2, mask_human)  # Robô = 2, Humano = 1\n",
    "    else:\n",
    "        # Resolver a máscara criando três classes: 0 (background), 1 (humano), 2 (robô)\n",
    "        mask = np.zeros_like(mask_human)  # Inicializar com background (0)\n",
    "        mask[mask_human == 1] = 1  # Definir classe humano como 1\n",
    "        mask[mask_robot == 1] = 2  # Definir classe robô como 2, sobrepõe humano se necessário\n",
    "\n",
    "    # Converte a máscara para um tensor PyTorch\n",
    "    mask_tensor = torch.tensor(mask, dtype=torch.long)\n",
    "    \n",
    "    return mask_tensor\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, masks, transform=None, mask_mode=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        self.mask_mode = mask_mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        #_, file_base_name = os.path.split(img_path)\n",
    "        file_base_name = os.path.split(img_path)[1].split(\".\")[0]\n",
    "        data, frame, camera = self.__get_mask_info__(file_base_name)\n",
    "        #print(data, frame, camera)\n",
    "        \n",
    "        mask_human, mask_robot = organize_masks(self.masks, data, int(camera), int(frame))\n",
    "        #mask_tensor = transform_masks(mask_human, mask_robot, self.mask_mode)\n",
    "        \n",
    "        m0 = np.zeros_like(mask_human)\n",
    "        final_mask = cv2.merge((m0, mask_robot, mask_human))\n",
    "        mask_tensor = np.transpose(final_mask, (2,0,1))\n",
    "        #print(f\"Mask human: {mask_human.shape}\")\n",
    "        #print(f\"Mask robot: {mask_robot.shape}\")\n",
    "\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        image = image.resize((256,256))\n",
    "        img_nd = np.array(image)\n",
    "\n",
    "        if len(img_nd.shape) == 2:\n",
    "            img_nd = np.expand_dims(img_nd, axis=2)\n",
    "\n",
    "        img_trans = img_nd.transpose((2, 0, 1))\n",
    "        if img_trans.max() > 1:\n",
    "            img_trans = img_trans / 255\n",
    "        #if self.transform:\n",
    "        #    image = self.transform(image)\n",
    "\n",
    "        return {\n",
    "                'image': torch.from_numpy(img_trans).type(torch.FloatTensor),\n",
    "                'mask': torch.from_numpy(mask_tensor).type(torch.FloatTensor)\n",
    "            }\n",
    "    \n",
    "    def __get_mask_info__(self, strx):\n",
    "        sub, act, rout, frame, camera = strx.split(\"_\")\n",
    "        return f\"{sub}_{act}_{rout}\", frame, camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders, K-fold, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_numero_regex(texto):\n",
    "    padrao = r'\\d+'\n",
    "    numeros = re.findall(padrao, texto)\n",
    "    if numeros:\n",
    "        return numeros[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_json_namefile(strx):\n",
    "\n",
    "    splited = strx.split(\"_\")\n",
    "    formated = f\"{int(extrair_numero_regex(splited[0]))}_{int(extrair_numero_regex(splited[1]))}_{int(extrair_numero_regex(splited[2]))}\"\n",
    "\n",
    "    if \"robot\" in strx:\n",
    "        formated += \"_robot\"\n",
    "        \n",
    "    return formated\n",
    "\n",
    "    \n",
    "def load_dataset_masks(pasta):\n",
    "    # Inicializa o dicionário para armazenar os dados\n",
    "    dados_json = {}\n",
    "\n",
    "    # Lista todos os arquivos na pasta\n",
    "    arquivos = os.listdir(pasta)\n",
    "\n",
    "    # Filtra apenas os arquivos JSON\n",
    "    arquivos_json = [arquivo for arquivo in arquivos if arquivo.endswith('.json')]\n",
    "\n",
    "    # Processa cada arquivo JSON encontrado\n",
    "    for arquivo_json in tqdm(arquivos_json):\n",
    "        caminho_completo = os.path.join(pasta, arquivo_json)\n",
    "        nome_arquivo = os.path.basename(arquivo_json)\n",
    "\n",
    "        # Carrega o conteúdo do arquivo JSON como um dicionário\n",
    "        with open(caminho_completo, 'r', encoding='utf-8') as f:\n",
    "            conteudo = json.load(f)\n",
    "        \n",
    "        # Adiciona ao dicionário final usando o nome do arquivo como chave\n",
    "        dados_json[process_json_namefile(nome_arquivo)] = conteudo\n",
    "    \n",
    "    return dados_json\n",
    "\n",
    "\n",
    "def load_image_paths(directory):\n",
    "    \"\"\"Loads all image paths from the specified directory.\"\"\"\n",
    "    path = Path(directory)\n",
    "    image_paths = list(path.glob('*.jpg'))\n",
    "    return [str(img) for img in image_paths]\n",
    "\n",
    "\n",
    "def group_images_by_prefix(image_paths):\n",
    "    \"\"\"Groups images by their prefix NUMSUBJECT_NUMACTIVITY_NUM_ROUTINE.\"\"\"\n",
    "    pattern = re.compile(r'(\\d+)_(\\d+)_(\\d+)_\\d+_\\d+.jpg')\n",
    "    grouped = {}\n",
    "    for img_path in image_paths:\n",
    "        match = pattern.search(os.path.basename(img_path))\n",
    "        if match:\n",
    "            prefix = f\"{match.group(1)}_{match.group(2)}_{match.group(3)}\"\n",
    "            if prefix not in grouped:\n",
    "                grouped[prefix] = []\n",
    "            grouped[prefix].append(img_path)\n",
    "    return list(grouped.values())\n",
    "\n",
    "\n",
    "def create_dataloaders(image_groups, dataset_masks, n_splits=5, batch_size=32, transform=None, mask_mode=None):\n",
    "    \"\"\"Creates DataLoaders for cross-validation.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    dataloaders = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(image_groups):\n",
    "        train_images = [img for i in train_index for img in image_groups[i]]\n",
    "        val_images = [img for i in val_index for img in image_groups[i]]\n",
    "        \n",
    "        train_dataset = CustomImageDataset(train_images, dataset_masks, transform, mask_mode)\n",
    "        val_dataset = CustomImageDataset(val_images, dataset_masks, transform, mask_mode)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        dataloaders.append((train_loader, val_loader))\n",
    "    \n",
    "    return dataloaders\n",
    "\n",
    "def get_sampled_loader(data_loader, sample_percentage):\n",
    "    # Calcula o tamanho da amostra\n",
    "    sample_size = int(len(data_loader.dataset) * sample_percentage)\n",
    "    remaining_size = len(data_loader.dataset) - sample_size\n",
    "    \n",
    "    # Divide o dataset em duas partes: amostra e restante\n",
    "    sample_dataset, _ = random_split(data_loader.dataset, [sample_size, remaining_size])\n",
    "    \n",
    "    # Cria um novo DataLoader para a amostra\n",
    "    sampled_loader = DataLoader(sample_dataset, batch_size=data_loader.batch_size, shuffle=True)\n",
    "    \n",
    "    return sampled_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(tensor):\n",
    "    return tensor.cpu().numpy().flatten()\n",
    "\n",
    "def calculate_dice_coefficient(outputs, targets, smooth=1e-6):\n",
    "    outputs = outputs.argmax(dim=1)  # Convert output logits to class predictions\n",
    "    num_classes = 3  # Defina o número de classes explicitamente\n",
    "\n",
    "    dice_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        intersection = ((outputs == i) & (targets == i)).float().sum()\n",
    "        union = (outputs == i).float().sum() + (targets == i).float().sum()\n",
    "        dice = (2. * intersection + smooth) / (union + smooth)\n",
    "        dice_per_class.append(dice.item())\n",
    "\n",
    "    mean_dice = sum(dice_per_class) / num_classes\n",
    "    return mean_dice, dice_per_class\n",
    "\n",
    "def calculate_iou(outputs, targets, smooth=1e-6):\n",
    "    outputs = outputs.argmax(dim=1)  # Convert output logits to class predictions\n",
    "    num_classes = 3  # Defina o número de classes explicitamente\n",
    "\n",
    "    iou_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        intersection = ((outputs == i) & (targets == i)).float().sum()\n",
    "        union = ((outputs == i) | (targets == i)).float().sum()\n",
    "        iou = (intersection + smooth) / (union + smooth)\n",
    "        iou_per_class.append(iou.item())\n",
    "\n",
    "    mean_iou = sum(iou_per_class) / num_classes\n",
    "    return mean_iou, iou_per_class\n",
    "\n",
    "def calculate_metrics(outputs, targets):\n",
    "    mean_dice, dice_per_class = calculate_dice_coefficient(outputs, targets)\n",
    "    mean_iou, iou_per_class = calculate_iou(outputs, targets)\n",
    "    return mean_dice, mean_iou, dice_per_class, iou_per_class\n",
    "\n",
    "def evaluation_v2(net, loader, device, pbar):\n",
    "    \"\"\"Evaluation without the densecrf with the dice coefficient\"\"\"\n",
    "    net.eval()\n",
    "    mask_type = torch.long\n",
    "    n_val = len(loader)  # the number of batch\n",
    "    tot_iou = 0\n",
    "    tot_dice = 0\n",
    "    tot = 0\n",
    "    metrics = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(loader, desc=f\"Validation...\", leave=False)\n",
    "        \n",
    "        for batch_idx, batch in enumerate(val_pbar):\n",
    "            imgs, true_masks = batch['image'], batch['mask']\n",
    "            imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                mask_pred = net(imgs)\n",
    "\n",
    "            if True == True:\n",
    "                true_masks = torch.argmax(true_masks, 1)\n",
    "                tot += F.cross_entropy(mask_pred, true_masks).item()\n",
    "\n",
    "                mean_dice, mean_iou, dice_per_class, iou_per_class = calculate_metrics(mask_pred, true_masks)\n",
    "                metrics.append((mean_dice, mean_iou, dice_per_class, iou_per_class))\n",
    "                \n",
    "                out = f'batch {batch_idx}/{len(loader)}'\n",
    "                \n",
    "                pbar.set_postfix(**{'Evaluating...': out})\n",
    "            else:\n",
    "                pred = torch.sigmoid(mask_pred)\n",
    "                pred = (pred > 0.5).float()\n",
    "                \n",
    "                tot_dice += dice_coeff(pred, true_masks).item()\n",
    "                tot_iou += iou(transform(pred), transform(true_masks))\n",
    "    \n",
    "    val_pbar.set_postfix({\"loss\": tot / n_val})\n",
    "\n",
    "    net.train()\n",
    "    return tot / n_val, metrics#, tot_dice / n_val, tot_iou / n_val\n",
    "\n",
    "\n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for individual examples\"\"\"\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "\n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    def backward(self, grad_output):\n",
    "\n",
    "        input, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "\n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
    "                         / (self.union * self.union)\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "\n",
    "        return grad_input, grad_target\n",
    "\n",
    "\n",
    "def dice_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    if input.is_cuda:\n",
    "        s = torch.FloatTensor(1).cuda().zero_()\n",
    "    else:\n",
    "        s = torch.FloatTensor(1).zero_()\n",
    "\n",
    "    for i, c in enumerate(zip(input, target)):\n",
    "        s = s + DiceCoeff().forward(c[0], c[1])\n",
    "\n",
    "    return s / (i + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novo código de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_checkpoint_info(checkpoint_dir):\n",
    "    \n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    folds = [int(fold_dir.replace('fold', '')) for fold_dir in os.listdir(checkpoint_dir)\n",
    "             if fold_dir.startswith('fold') and os.path.isdir(os.path.join(checkpoint_dir, fold_dir))]\n",
    "    if not folds:\n",
    "        return 0, 0, float('inf')  # No existing folds, start from scratch\n",
    "    last_fold = max(folds)\n",
    "    last_checkpoint_path = os.path.join(checkpoint_dir, f\"fold{last_fold}\", \"last_training_loss.pth\")\n",
    "    if os.path.isfile(last_checkpoint_path):\n",
    "        epoch, fold, best_val_loss = load_checkpoint(None, None, last_checkpoint_path, return_model=False)\n",
    "        return epoch+1, last_fold-1, best_val_loss\n",
    "    else:\n",
    "        return 0, last_fold - 1, float('inf')  # No valid checkpoint, restart the last fold\n",
    "\n",
    "def load_checkpoint(model, optimizer, checkpoint_path, return_model=True):\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(f\"Loading checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        if return_model and model is not None and optimizer is not None:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        fold = checkpoint['fold']\n",
    "        best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "        return epoch, fold, best_val_loss\n",
    "    else:\n",
    "        print(f\"No checkpoint found at: {checkpoint_path}\")\n",
    "        return 0, 0, float('inf')\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, fold, is_best, checkpoint_dir):\n",
    "    # Cria o diretório de checkpoints e subdiretório para cada fold, se não existirem\n",
    "    fold_dir = os.path.join(checkpoint_dir, f\"fold{fold+1}\")\n",
    "    os.makedirs(fold_dir, exist_ok=True)\n",
    "    \n",
    "    # Caminho para o último checkpoint de treinamento\n",
    "    last_checkpoint_path = os.path.join(fold_dir, \"last_training_loss.pth\")\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'fold': fold,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, last_checkpoint_path)\n",
    "\n",
    "    if is_best:\n",
    "        best_checkpoint_path = os.path.join(fold_dir, \"best_val_loss.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'fold': fold,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, best_checkpoint_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_csv(loss_train, loss_val, metrics_val, checkpoint_dir, fold, epoch):\n",
    "    # Cria o diretório de checkpoints, se não existir\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Separar as métricas\n",
    "    #mean_dice_train, mean_iou_train, dice_per_class_train, iou_per_class_train = zip(*metrics_train)\n",
    "    mean_dice_val, mean_iou_val, dice_per_class_val, iou_per_class_val = zip(*metrics_val)\n",
    "    \n",
    "    # Calcular as médias\n",
    "    #avg_dice_train = np.mean(mean_dice_train)\n",
    "    #avg_iou_train = np.mean(mean_iou_train)\n",
    "    avg_dice_val = np.mean(mean_dice_val)\n",
    "    avg_iou_val = np.mean(mean_iou_val)\n",
    "    \n",
    "    # Preparar os dados para o DataFrame\n",
    "    data = {\n",
    "        'epoch': epoch,\n",
    "        'loss_train': loss_train,\n",
    "        'loss_val': loss_val,\n",
    "        #'avg_dice_train': avg_dice_train,\n",
    "        #'avg_iou_train': avg_iou_train,\n",
    "        'avg_dice_val': avg_dice_val,\n",
    "        'avg_iou_val': avg_iou_val,\n",
    "    }\n",
    "\n",
    "    # Adicionar métricas por classe\n",
    "    for class_index in range(3):  # Assumindo 3 classes: fundo, humano, robô\n",
    "        #data[f'dice_class_{class_index}_train'] = np.mean([d[class_index] for d in dice_per_class_train])\n",
    "        #data[f'iou_class_{class_index}_train'] = np.mean([i[class_index] for i in iou_per_class_train])\n",
    "        data[f'dice_class_{class_index}_val'] = np.mean([d[class_index] for d in dice_per_class_val])\n",
    "        data[f'iou_class_{class_index}_val'] = np.mean([i[class_index] for i in iou_per_class_val])\n",
    "    \n",
    "    # Converter para DataFrame\n",
    "    metrics_df = pd.DataFrame([data])\n",
    "\n",
    "    csv_path = os.path.join(checkpoint_dir, f\"fold{fold+1}_report.csv\")\n",
    "    if not os.path.isfile(csv_path):\n",
    "        metrics_df.to_csv(csv_path, index=False)\n",
    "    else:\n",
    "        metrics_df.to_csv(csv_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, dataloaders, epochs, criterion, learning_rate, dir_checkpoint, sampling):\n",
    "    \n",
    "    start_epoch, start_fold, best_val_loss = get_last_checkpoint_info(dir_checkpoint)\n",
    "    \n",
    "    for fold in range(start_fold, len(dataloaders)):\n",
    "        \n",
    "        net = copy.deepcopy(model).to(device)\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "        #net = model\n",
    "\n",
    "        train_loader, val_loader = dataloaders[fold]\n",
    "        \n",
    "        if sampling is not None:\n",
    "            train_loader = get_sampled_loader(train_loader, sampling)\n",
    "            val_loader = get_sampled_loader(val_loader, sampling)\n",
    "        \n",
    "        if fold == start_fold and start_epoch > 0:\n",
    "            start_epoch, _, best_val_loss = load_checkpoint(model, optimizer, os.path.join(dir_checkpoint, f\"fold{fold+1}\", \"last_training_loss.pth\"))\n",
    "            best_loss = best_val_loss\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            best_loss = 32000000\n",
    "\n",
    "        global_step = 0\n",
    "        \n",
    "        \n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            net.train()\n",
    "\n",
    "            epoch_loss = 0\n",
    "            with tqdm(total=len(train_loader.dataset), desc=f'Fold {fold+1}/{len(dataloaders)} | Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "                for batch in train_loader:\n",
    "                    imgs = batch['image']\n",
    "                    true_masks = batch['mask']\n",
    "                    #print(imgs.shape,true_masks.shape)\n",
    "\n",
    "                    imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "                    mask_type = torch.long\n",
    "                    true_masks = true_masks.to(device=device, dtype=mask_type)\n",
    "\n",
    "                    masks_pred = net(imgs)\n",
    "                    true_masks = torch.argmax(true_masks, 1)\n",
    "\n",
    "                    loss = criterion(masks_pred, true_masks)\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_value_(net.parameters(), 0.1)\n",
    "                    optimizer.step()\n",
    "\n",
    "                    pbar.update(imgs.shape[0])\n",
    "                    global_step += 1\n",
    "                    \n",
    "\n",
    "                val_lss, val_metrics = evaluation_v2(net, val_loader, device, pbar)\n",
    "\n",
    "            if val_lss < best_loss:\n",
    "                best_loss = val_lss\n",
    "                save_checkpoint(model, optimizer, epoch, fold, True, dir_checkpoint)\n",
    "\n",
    "            save_checkpoint(model, optimizer, epoch, fold, True, dir_checkpoint)\n",
    "            save_metrics_to_csv(epoch_loss/len(train_loader.dataset), val_lss, val_metrics, dir_checkpoint, fold, epoch)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## QUAL PC ESTOU USANDO???\n",
    "PC = 'home'\n",
    "\n",
    "if PC == 'home':\n",
    "    batch_size = 4\n",
    "    image_directory = \"C:/Users/iagor/Documents/git/data-definer/out/\"\n",
    "    mask_directory = \"C:/Users/iagor/Documents/git/human-segmentation-sam/out/\"\n",
    "else: \n",
    "    batch_size = 256\n",
    "    image_directory = \"/home/iago/PhD/data-definer/out/\"\n",
    "    mask_directory = \"/home/iago/PhD/segment-humans-sam/out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## OUTRAS VARIAVEIS\n",
    "n_splits = 5\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sampling = None\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## DATASET\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()  # Converte automaticamente para o intervalo [0, 1]\n",
    "])\n",
    "\n",
    "dataset_masks = load_dataset_masks(mask_directory)\n",
    "mask_mode = \"entropy\"\n",
    "image_paths = load_image_paths(image_directory)\n",
    "image_groups = group_images_by_prefix(image_paths)\n",
    "dataloaders = create_dataloaders(image_groups, dataset_masks, n_splits, batch_size, transform, mask_mode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=3, n_classes=3, bilinear=True)\n",
    "model.to(device)\n",
    "model_name = \"unet\"\n",
    "\n",
    "checkpoint_dir = f\"checkpoints/{model_name}/\"\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, device, dataloaders, num_epochs, criterion, learning_rate, checkpoint_dir, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_masks(dataloader):\n",
    "    # Obtenha o primeiro batch do dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    images, masks = next(dataiter)\n",
    "    \n",
    "    batch_size = images.size(0)\n",
    "    \n",
    "    fig, axs = plt.subplots(batch_size, 2, figsize=(10, batch_size * 5))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # Converta o tensor da imagem para numpy para exibição\n",
    "        img = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        mask = masks[i].squeeze(0).cpu().numpy()  # Remove a dimensão extra da máscara\n",
    "\n",
    "        print(img.shape)\n",
    "        print(f\"{mask.shape} - {np.unique(mask)}\")\n",
    "        \n",
    "        # Normalize the image for display purposes (optional)\n",
    "        img = img - img.min()\n",
    "        img = img / img.max()\n",
    "        \n",
    "        if batch_size == 1:\n",
    "            axs[0].imshow(img)\n",
    "            axs[0].set_title(f\"Image {i + 1}\")\n",
    "            axs[0].axis('off')\n",
    "            \n",
    "            axs[1].imshow(mask, cmap='gray')\n",
    "            axs[1].set_title(f\"Mask {i + 1}\")\n",
    "            axs[1].axis('off')\n",
    "        else:\n",
    "            axs[i, 0].imshow(img)\n",
    "            axs[i, 0].set_title(f\"Image {i + 1}\")\n",
    "            axs[i, 0].axis('off')\n",
    "            \n",
    "            axs[i, 1].imshow(mask, cmap='gray')\n",
    "            axs[i, 1].set_title(f\"Mask {i + 1}\")\n",
    "            axs[i, 1].axis('off')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_masks(dataloaders[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(dataloaders[0][0])\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_sampled_loader(dataloaders[0][0], sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = dataloaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)  # substitua `train_loader` pelo seu DataLoader\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in images:\n",
    "    print(im.shape)\n",
    "    print(torch.unique(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshou(img):\n",
    "    img = img / 2 + 0.5  # Dessormalizar (se as imagens foram normalizadas)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "imshou(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshou(torchvision.utils.make_grid(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iago",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
